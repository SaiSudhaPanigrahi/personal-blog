<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title>Test Report</title>
    <link href="assets/style.css" rel="stylesheet" type="text/css"/></head>
  <body onLoad="init()">
    <script>/* This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this file,
 * You can obtain one at http://mozilla.org/MPL/2.0/. */


function toArray(iter) {
    if (iter === null) {
        return null;
    }
    return Array.prototype.slice.call(iter);
}

function find(selector, elem) {
    if (!elem) {
        elem = document;
    }
    return elem.querySelector(selector);
}

function find_all(selector, elem) {
    if (!elem) {
        elem = document;
    }
    return toArray(elem.querySelectorAll(selector));
}

function sort_column(elem) {
    toggle_sort_states(elem);
    var colIndex = toArray(elem.parentNode.childNodes).indexOf(elem);
    var key;
    if (elem.classList.contains('numeric')) {
        key = key_num;
    } else if (elem.classList.contains('result')) {
        key = key_result;
    } else {
        key = key_alpha;
    }
    sort_table(elem, key(colIndex));
}

function show_all_extras() {
    find_all('.col-result').forEach(show_extras);
}

function hide_all_extras() {
    find_all('.col-result').forEach(hide_extras);
}

function show_extras(colresult_elem) {
    var extras = colresult_elem.parentNode.nextElementSibling;
    var expandcollapse = colresult_elem.firstElementChild;
    extras.classList.remove("collapsed");
    expandcollapse.classList.remove("expander");
    expandcollapse.classList.add("collapser");
}

function hide_extras(colresult_elem) {
    var extras = colresult_elem.parentNode.nextElementSibling;
    var expandcollapse = colresult_elem.firstElementChild;
    extras.classList.add("collapsed");
    expandcollapse.classList.remove("collapser");
    expandcollapse.classList.add("expander");
}

function show_filters() {
    var filter_items = document.getElementsByClassName('filter');
    for (var i = 0; i < filter_items.length; i++)
        filter_items[i].hidden = false;
}

function add_collapse() {
    // Add links for show/hide all
    var resulttable = find('table#results-table');
    var showhideall = document.createElement("p");
    showhideall.innerHTML = '<a href="javascript:show_all_extras()">Show all details</a> / ' +
                            '<a href="javascript:hide_all_extras()">Hide all details</a>';
    resulttable.parentElement.insertBefore(showhideall, resulttable);

    // Add show/hide link to each result
    find_all('.col-result').forEach(function(elem) {
        var collapsed = get_query_parameter('collapsed') || 'Passed';
        var extras = elem.parentNode.nextElementSibling;
        var expandcollapse = document.createElement("span");
        if (collapsed.includes(elem.innerHTML)) {
            extras.classList.add("collapsed");
            expandcollapse.classList.add("expander");
        } else {
            expandcollapse.classList.add("collapser");
        }
        elem.appendChild(expandcollapse);

        elem.addEventListener("click", function(event) {
            if (event.currentTarget.parentNode.nextElementSibling.classList.contains("collapsed")) {
                show_extras(event.currentTarget);
            } else {
                hide_extras(event.currentTarget);
            }
        });
    })
}

function get_query_parameter(name) {
    var match = RegExp('[?&]' + name + '=([^&]*)').exec(window.location.search);
    return match && decodeURIComponent(match[1].replace(/\+/g, ' '));
}

function init () {
    reset_sort_headers();

    add_collapse();

    show_filters();

    toggle_sort_states(find('.initial-sort'));

    find_all('.sortable').forEach(function(elem) {
        elem.addEventListener("click",
                              function(event) {
                                  sort_column(elem);
                              }, false)
    });

};

function sort_table(clicked, key_func) {
    var rows = find_all('.results-table-row');
    var reversed = !clicked.classList.contains('asc');
    var sorted_rows = sort(rows, key_func, reversed);
    /* Whole table is removed here because browsers acts much slower
     * when appending existing elements.
     */
    var thead = document.getElementById("results-table-head");
    document.getElementById('results-table').remove();
    var parent = document.createElement("table");
    parent.id = "results-table";
    parent.appendChild(thead);
    sorted_rows.forEach(function(elem) {
        parent.appendChild(elem);
    });
    document.getElementsByTagName("BODY")[0].appendChild(parent);
}

function sort(items, key_func, reversed) {
    var sort_array = items.map(function(item, i) {
        return [key_func(item), i];
    });
    var multiplier = reversed ? -1 : 1;

    sort_array.sort(function(a, b) {
        var key_a = a[0];
        var key_b = b[0];
        return multiplier * (key_a >= key_b ? 1 : -1);
    });

    return sort_array.map(function(item) {
        var index = item[1];
        return items[index];
    });
}

function key_alpha(col_index) {
    return function(elem) {
        return elem.childNodes[1].childNodes[col_index].firstChild.data.toLowerCase();
    };
}

function key_num(col_index) {
    return function(elem) {
        return parseFloat(elem.childNodes[1].childNodes[col_index].firstChild.data);
    };
}

function key_result(col_index) {
    return function(elem) {
        var strings = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed',
                       'Skipped', 'Passed'];
        return strings.indexOf(elem.childNodes[1].childNodes[col_index].firstChild.data);
    };
}

function reset_sort_headers() {
    find_all('.sort-icon').forEach(function(elem) {
        elem.parentNode.removeChild(elem);
    });
    find_all('.sortable').forEach(function(elem) {
        var icon = document.createElement("div");
        icon.className = "sort-icon";
        icon.textContent = "vvv";
        elem.insertBefore(icon, elem.firstChild);
        elem.classList.remove("desc", "active");
        elem.classList.add("asc", "inactive");
    });
}

function toggle_sort_states(elem) {
    //if active, toggle between asc and desc
    if (elem.classList.contains('active')) {
        elem.classList.toggle('asc');
        elem.classList.toggle('desc');
    }

    //if inactive, reset all other functions and add ascending active
    if (elem.classList.contains('inactive')) {
        reset_sort_headers();
        elem.classList.remove('inactive');
        elem.classList.add('active');
    }
}

function is_all_rows_hidden(value) {
  return value.hidden == false;
}

function filter_table(elem) {
    var outcome_att = "data-test-result";
    var outcome = elem.getAttribute(outcome_att);
    class_outcome = outcome + " results-table-row";
    var outcome_rows = document.getElementsByClassName(class_outcome);

    for(var i = 0; i < outcome_rows.length; i++){
        outcome_rows[i].hidden = !elem.checked;
    }

    var rows = find_all('.results-table-row').filter(is_all_rows_hidden);
    var all_rows_hidden = rows.length == 0 ? true : false;
    var not_found_message = document.getElementById("not-found-message");
    not_found_message.hidden = !all_rows_hidden;
}
</script>
    <h1>test-report.html</h1>
    <p>Report generated on 20-Jun-2018 at 12:25:43 by<a href="https://pypi.python.org/pypi/pytest-html"> pytest-html</a> v1.19.0</p>
    <h2>Environment</h2>
    <table id="environment">
      <tr>
        <td>Packages</td>
        <td>{&apos;pytest&apos;: &apos;3.6.1&apos;, &apos;py&apos;: &apos;1.5.3&apos;, &apos;pluggy&apos;: &apos;0.6.0&apos;}</td></tr>
      <tr>
        <td>Platform</td>
        <td>Linux-4.9.87-linuxkit-aufs-x86_64-with-debian-9.4</td></tr>
      <tr>
        <td>Plugins</td>
        <td>{&apos;metadata&apos;: &apos;1.7.0&apos;, &apos;html&apos;: &apos;1.19.0&apos;}</td></tr>
      <tr>
        <td>Python</td>
        <td>3.6.5</td></tr></table>
    <h2>Summary</h2>
    <p>9 tests ran in 4.41 seconds. </p>
    <p class="filter" hidden="true">(Un)check the boxes to filter the results.</p><input checked="true" class="filter" data-test-result="passed" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="passed">2 passed</span>, <input checked="true" class="filter" data-test-result="skipped" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="skipped">0 skipped</span>, <input checked="true" class="filter" data-test-result="failed" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="failed">7 failed</span>, <input checked="true" class="filter" data-test-result="error" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="error">17 errors</span>, <input checked="true" class="filter" data-test-result="xfailed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="xfailed">0 expected failures</span>, <input checked="true" class="filter" data-test-result="xpassed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="xpassed">0 unexpected passes</span>
    <h2>Results</h2>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable result initial-sort" col="result">Result</th>
          <th class="sortable" col="name">Test</th>
          <th class="sortable numeric" col="duration">Duration</th>
          <th>Links</th></tr>
        <tr hidden="true" id="not-found-message">
          <th colspan="4">No results found. Try to check the filters</th></tr></thead>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_about.py::test_about_page_url::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f81800f4160&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/about&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f81800e4dd8&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f81800f4fd0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f81800f4160&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/about&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f81800f4fd0&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f81800f4208&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/about&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/about&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/>data = b&#x27;GET /about HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817e8f30b8&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f81800e4dd8&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f81800f4160&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/about&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f81800e4dd8&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f81800f4fd0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/about&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f81800f4160&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817e958f48&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /about (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def about_url_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from `about` page&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _about).response()<br/><br/>tests/plugins/about.py:12: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817e8f30b8&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f81800e4dd8&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /about (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_about.py::test_about_page_content::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f81800f4160&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/about&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f81800e4dd8&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f81800f4fd0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f81800f4160&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/about&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f81800f4fd0&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f81800f4208&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/about&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/about&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/>data = b&#x27;GET /about HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817e8f30b8&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f81800e4dd8&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f81800f4160&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/about&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f81800e4dd8&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f81800f4fd0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/about&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f81800f4160&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817e958f48&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /about (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def about_url_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from `about` page&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _about).response()<br/><br/>tests/plugins/about.py:12: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817e8f30b8&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f81800e4dd8&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /about (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f81800f4ef0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_account.py::test_account_page_url::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd5b4e0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/account&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b5c0&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b780&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd5b4e0&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/account&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b780&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b7f0&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/account&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/account&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/>data = b&#x27;GET /account HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817dd5b278&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b5c0&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd5b4e0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/account&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b5c0&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b780&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/account&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd5b4e0&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817dbf9dc8&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /account (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def account_url_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from `account` page&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _account).response()<br/><br/>tests/plugins/account.py:12: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817dd5b278&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b5c0&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /account (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_account.py::test_account_page_content::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd5b4e0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/account&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b5c0&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b780&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd5b4e0&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/account&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b780&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b7f0&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/account&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/account&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/>data = b&#x27;GET /account HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817dd5b278&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b5c0&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd5b4e0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/account&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b5c0&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b780&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/account&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd5b4e0&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817dbf9dc8&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /account (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def account_url_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from `account` page&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _account).response()<br/><br/>tests/plugins/account.py:12: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817dd5b278&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd5b5c0&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /account (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817dd5b7b8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_home.py::test_default_home_page_url::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd9dbe0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9db00&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9def0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd9dbe0&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9def0&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9df60&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/>data = b&#x27;GET / HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817dd9d978&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9db00&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd9dbe0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9db00&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9def0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd9dbe0&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817db343c8&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: / (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def default_home_url_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from `default home` page&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint).response()<br/><br/>tests/plugins/home.py:12: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817dd9d978&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9db00&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: / (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_home.py::test_home_page_url::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817daf2e48&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/home&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817daf2dd8&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817db0b160&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817daf2e48&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/home&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817db0b160&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817db0b1d0&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/home&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/home&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/>data = b&#x27;GET /home HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817daf2b70&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817daf2dd8&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817daf2e48&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/home&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817daf2dd8&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817db0b160&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/home&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817daf2e48&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817da2fa88&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /home (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def home_url_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from `home` page&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _home).response()<br/><br/>tests/plugins/home.py:19: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817daf2b70&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817daf2dd8&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /home (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_home.py::test_default_home_page_content::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd9dbe0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9db00&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9def0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd9dbe0&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9def0&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9df60&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/>data = b&#x27;GET / HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817dd9d978&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9db00&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd9dbe0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9db00&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9def0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817dd9dbe0&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817db343c8&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: / (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def default_home_url_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from `default home` page&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint).response()<br/><br/>tests/plugins/home.py:12: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817dd9d978&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817dd9db00&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: / (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817dd9df28&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_home.py::test_home_page_content::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817daf2e48&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/home&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817daf2dd8&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817db0b160&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817daf2e48&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/home&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817db0b160&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817db0b1d0&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/home&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/home&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/>data = b&#x27;GET /home HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817daf2b70&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817daf2dd8&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817daf2e48&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/home&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817daf2dd8&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817db0b160&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/home&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817daf2e48&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817da2fa88&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /home (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def home_url_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from `home` page&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _home).response()<br/><br/>tests/plugins/home.py:19: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817daf2b70&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817daf2dd8&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /home (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817db0b198&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_login.py::test_login_page_url::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d968128&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/login&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d9659e8&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d9681d0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d968128&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/login&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d9681d0&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d968470&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/login&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/login&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/>data = b&#x27;GET /login HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d965ef0&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d9659e8&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d968128&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/login&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d9659e8&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d9681d0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/login&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d968128&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817d92c708&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /login (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def login_url_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from `login` page&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _login).response()<br/><br/>tests/plugins/login.py:12: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d965ef0&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d9659e8&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /login (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_login.py::test_login_page_content::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d968128&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/login&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d9659e8&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d9681d0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d968128&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/login&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d9681d0&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d968470&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/login&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/login&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/>data = b&#x27;GET /login HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d965ef0&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d9659e8&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d968128&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/login&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d9659e8&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d9681d0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/login&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d968128&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817d92c708&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /login (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def login_url_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from `login` page&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _login).response()<br/><br/>tests/plugins/login.py:12: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d965ef0&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d9659e8&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /login (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d968400&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_posts.py::test_new_post::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d752ba8&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d752860&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/new&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d752780&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d752b70&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d752860&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817d752ba8&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/new&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d752b70&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d752be0&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d752ba8&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/new&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d752ba8&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/new&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d752ba8&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d752ba8&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d752ba8&gt;<br/>data = b&#x27;GET /post/new HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d752ba8&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d752ba8&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817d752ba8&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d7525f8&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d752780&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d752860&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/new&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d752780&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d752b70&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/post/new&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d752ba8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d752860&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817d54fcc8&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /post/new (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d752ba8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def new_post(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from ``new post`` page.&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _new_post).response()<br/><br/>tests/plugins/posts.py:15: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d7525f8&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d752780&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /post/new (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d752ba8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_posts.py::test_existent_post::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d582c88&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d582978&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/4&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d582908&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d582c50&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d582978&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817d582c88&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/4&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d582c50&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d582cc0&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d582c88&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/4&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d582c88&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/4&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d582c88&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d582c88&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d582c88&gt;<br/>data = b&#x27;GET /post/4 HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d582c88&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d582c88&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817d582c88&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d5826a0&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d582908&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d582978&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/4&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d582908&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d582c50&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/post/4&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d582c88&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d582978&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817d41b248&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /post/4 (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d582c88&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def existent_post_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from existent post&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _exist_post_id).response()<br/><br/>tests/plugins/posts.py:22: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d5826a0&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d582908&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /post/4 (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d582c88&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_posts.py::test_non_existent_post::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d48ed30&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d48e9e8&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/NONE&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d48e908&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d48ecf8&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d48e9e8&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817d48ed30&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/NONE&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d48ecf8&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d48ed68&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d48ed30&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/NONE&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d48ed30&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/NONE&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d48ed30&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d48ed30&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d48ed30&gt;<br/>data = b&#x27;GET /post/NONE HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d48ed30&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d48ed30&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817d48ed30&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d48e780&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d48e908&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d48e9e8&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/NONE&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d48e908&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d48ecf8&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/post/NONE&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d48ed30&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d48e9e8&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817d463a08&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /post/NONE (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d48ed30&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def non_existent_post_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from non existent post.&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _non_exist_post_id).response()<br/><br/>tests/plugins/posts.py:29: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d48e780&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d48e908&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /post/NONE (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d48ed30&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_posts.py::test_update_existent_post::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d37bdd8&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d37ba90&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/4/update&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d37b9b0&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d37bda0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d37ba90&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817d37bdd8&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/4/update&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d37bda0&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d37be10&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d37bdd8&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/4/update&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d37bdd8&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/4/update&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d37bdd8&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d37bdd8&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d37bdd8&gt;<br/>data = b&#x27;GET /post/4/update HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d37bdd8&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d37bdd8&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817d37bdd8&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d37b828&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d37b9b0&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d37ba90&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/4/update&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d37b9b0&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d37bda0&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/post/4/update&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d37bdd8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d37ba90&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817d3a6988&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /post/4/update (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d37bdd8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def update_existent_post_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from ``update`` post page with existent post.&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _exist_post_id + _update_post).response()<br/><br/>tests/plugins/posts.py:36: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d37b828&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d37b9b0&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /post/4/update (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d37bdd8&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_posts.py::test_update_non_existent_post::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d21be80&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d21bb38&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/NONE/update&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d21ba58&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d21be48&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d21bb38&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817d21be80&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/NONE/update&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d21be48&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d21beb8&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d21be80&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/NONE/update&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d21be80&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/NONE/update&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d21be80&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d21be80&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d21be80&gt;<br/>data = b&#x27;GET /post/NONE/update HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d21be80&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d21be80&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817d21be80&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d21b8d0&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d21ba58&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d21bb38&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/post/NONE/update&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d21ba58&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d21be48&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/post/NONE/update&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d21be80&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d21bb38&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817d235c88&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /post/NONE/update (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d21be80&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def update_non_existent_post_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from ``update`` post page with non existent post.&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _non_exist_post_id + _update_post).response()<br/><br/>tests/plugins/posts.py:43: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d21b8d0&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d21ba58&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /post/NONE/update (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d21be80&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_register.py::test_register_page_url::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d345b00&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/register&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345a20&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345e10&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d345b00&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/register&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345e10&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345e80&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/register&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/register&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/>data = b&#x27;GET /register HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d345898&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345a20&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d345b00&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/register&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345a20&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345e10&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/register&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d345b00&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817d172888&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /register (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def register_url_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from `register` page&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _register).response()<br/><br/>tests/plugins/register.py:12: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d345898&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345a20&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /register (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="error results-table-row">
        <tr>
          <td class="col-result">Error</td>
          <td class="col-name">tests/functional/smoke/test_register.py::test_register_page_content::setup</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d345b00&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/register&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345a20&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345e10&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d345b00&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/register&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345e10&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345e80&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/register&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/register&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/>data = b&#x27;GET /register HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d345898&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345a20&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d345b00&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/register&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345a20&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345e10&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/register&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d345b00&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817d172888&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /register (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>url_endpoint = &#x27;http://localhost:5000&#x27;<br/><br/>    @pytest.fixture(scope=&#x27;module&#x27;)<br/>    def register_url_response(url_endpoint: str) -&gt; Response:<br/>        &quot;&quot;&quot;Represent response from `register` page&quot;&quot;&quot;<br/>    <br/>&gt;       return Get(url_endpoint + _register).response()<br/><br/>tests/plugins/register.py:12: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d345898&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d345a20&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /register (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d345e48&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/functional/smoke/test_login.py::test_login_user</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d6cfbe0&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d6cf8d0&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/login&#x27;, body = &#x27;data=email&amp;data=password&amp;data=submit&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;36&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d6cf860&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d6cfba8&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d6cf8d0&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817d6cfbe0&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/login&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d6cfba8&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: &#x27;data=email&amp;data=password&amp;data=submit&#x27;, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;...cept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;36&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d6cfc18&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d6cfbe0&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/login&#x27;, body = &#x27;data=email&amp;data=password&amp;data=submit&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;36&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d6cfbe0&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/login&#x27;, body = b&#x27;data=email&amp;data=password&amp;data=submit&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;36&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d6cfbe0&gt;<br/>message_body = b&#x27;data=email&amp;data=password&amp;data=submit&#x27;<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d6cfbe0&gt;<br/>message_body = b&#x27;data=email&amp;data=password&amp;data=submit&#x27;, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d6cfbe0&gt;<br/>data = b&#x27;POST /login HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate...Accept: */*\r\nConnection: keep-alive\r\nContent-Length: 36\r\nContent-Type: application/x-www-form-urlencoded\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d6cfbe0&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d6cfbe0&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817d6cfbe0&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d6cf5f8&gt;<br/>request = &lt;PreparedRequest [POST]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d6cf860&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d6cf8d0&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/login&#x27;, body = &#x27;data=email&amp;data=password&amp;data=submit&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;36&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d6cf860&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d6cfba8&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;POST&#x27;, url = &#x27;/login&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d6cfbe0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d6cf8d0&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817d7c2488&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /login (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d6cfbe0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>login_user_request = &lt;server.api.requests.Post object at 0x7f817d6cf390&gt;<br/>success = 200<br/><br/>    @pytest.mark.smoke<br/>    def test_login_user(login_user_request: Request, success: int) -&gt; None:<br/>        data: Dict[str, str] = {&quot;email&quot;: &quot;admin@blog.com&quot;,<br/>                                &quot;password&quot;: &quot;password&quot;,<br/>                                &quot;submit&quot;: &quot;Login&quot;}<br/>    <br/>&gt;       assert login_user_request.response(data=data).status_code() == success<br/><br/>tests/functional/smoke/test_login.py:25: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:34: in response<br/>    return HttpResponse(self._session.post(self._url, kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:559: in post<br/>    return self.request(&#x27;POST&#x27;, url, data=data, json=json, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d6cf5f8&gt;<br/>request = &lt;PreparedRequest [POST]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d6cf860&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /login (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d6cfbe0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/functional/smoke/test_register.py::test_register_user</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf6e668&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cf6e2e8&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/register&#x27;<br/>body = &#x27;data=username&amp;data=password&amp;data=confirm_password&amp;data=submit&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;61&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf6e208&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf6e630&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cf6e2e8&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf6e668&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/register&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf6e630&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: &#x27;data=username&amp;data=password&amp;data=confirm_password&amp;data=submit&#x27;, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2...cept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;61&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf6e6a0&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf6e668&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/register&#x27;<br/>body = &#x27;data=username&amp;data=password&amp;data=confirm_password&amp;data=submit&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;61&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf6e668&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/register&#x27;<br/>body = b&#x27;data=username&amp;data=password&amp;data=confirm_password&amp;data=submit&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;61&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf6e668&gt;<br/>message_body = b&#x27;data=username&amp;data=password&amp;data=confirm_password&amp;data=submit&#x27;<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf6e668&gt;<br/>message_body = b&#x27;data=username&amp;data=password&amp;data=confirm_password&amp;data=submit&#x27;<br/>encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf6e668&gt;<br/>data = b&#x27;POST /register HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, defl...Accept: */*\r\nConnection: keep-alive\r\nContent-Length: 61\r\nContent-Type: application/x-www-form-urlencoded\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf6e668&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf6e668&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817cf6e668&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817cf6e080&gt;<br/>request = &lt;PreparedRequest [POST]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf6e208&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cf6e2e8&gt;<br/>method = &#x27;POST&#x27;, url = &#x27;/register&#x27;<br/>body = &#x27;data=username&amp;data=password&amp;data=confirm_password&amp;data=submit&#x27;<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;, &#x27;Content-Length&#x27;: &#x27;61&#x27;, &#x27;Content-Type&#x27;: &#x27;application/x-www-form-urlencoded&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf6e208&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf6e630&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;POST&#x27;, url = &#x27;/register&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817cf6e668&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cf6e2e8&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817cf516c8&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /register (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817cf6e668&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>register_user_request = &lt;server.api.requests.Post object at 0x7f817cf68f28&gt;<br/>success = 200<br/><br/>    @pytest.mark.smoke<br/>    def test_register_user(register_user_request: Request, success: int) -&gt; None:<br/>        data: Dict[str, str] = {&quot;username&quot;: &quot;vyah@blog.com&quot;,<br/>                                &quot;password&quot;: &quot;password&quot;,<br/>                                &quot;confirm_password&quot;: &quot;password&quot;,<br/>                                &quot;submit&quot;: &quot;Sing+Up&quot;}<br/>    <br/>&gt;       assert register_user_request.response(data=data).status_code() == success<br/><br/>tests/functional/smoke/test_register.py:26: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:34: in response<br/>    return HttpResponse(self._session.post(self._url, kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:559: in post<br/>    return self.request(&#x27;POST&#x27;, url, data=data, json=json, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817cf6e080&gt;<br/>request = &lt;PreparedRequest [POST]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf6e208&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: /register (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817cf6e668&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/non_functional/performance/test_endurance.py::test_endurance</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf89f60&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cf89be0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf89b00&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf89f28&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cf89be0&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf89f60&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf89f28&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf89f98&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf89f60&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf89f60&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf89f60&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf89f60&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf89f60&gt;<br/>data = b&#x27;GET / HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf89f60&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cf89f60&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817cf89f60&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817cf89978&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf89b00&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cf89be0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf89b00&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf89f28&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817cf89f60&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cf89be0&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817d001a88&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: / (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817cf89f60&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>default_home_request = &lt;server.api.requests.Get object at 0x7f817cf89780&gt;<br/>success = 200<br/><br/>    @pytest.mark.performance<br/>    def test_endurance(default_home_request: Request, success: int) -&gt; None:<br/>        times: int = _xtime<br/>        while times &gt; _zero:<br/>&gt;           assert default_home_request.response().status_code() == success<br/><br/>tests/non_functional/performance/test_endurance.py:13: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817cf89978&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cf89b00&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: / (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817cf89f60&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/non_functional/performance/test_load.py::test_load</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0029b0&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d002630&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d002550&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d002978&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d002630&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0029b0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d002978&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d0029e8&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0029b0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0029b0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0029b0&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0029b0&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0029b0&gt;<br/>data = b&#x27;GET / HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0029b0&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0029b0&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817d0029b0&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d0023c8&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d002550&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d002630&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d002550&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d002978&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d0029b0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d002630&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817ce70a48&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: / (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d0029b0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>default_home_request = &lt;server.api.requests.Get object at 0x7f817d002160&gt;<br/>success = 200<br/><br/>    @pytest.mark.performance<br/>    def test_load(default_home_request: Request, success: int) -&gt; None:<br/>        t1: float = time.time()<br/>        times: int = _xtime<br/>        while times &gt; _zero:<br/>&gt;           assert default_home_request.response().status_code() == success<br/><br/>tests/non_functional/performance/test_load.py:16: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d0023c8&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d002550&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: / (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d0029b0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/non_functional/performance/test_smoke.py::test_smoke</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0b6be0&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d0b6860&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d0b6780&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d0b6ba8&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d0b6860&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0b6be0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d0b6ba8&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d0b6c18&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0b6be0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0b6be0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0b6be0&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0b6be0&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0b6be0&gt;<br/>data = b&#x27;GET / HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0b6be0&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817d0b6be0&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817d0b6be0&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d0b65f8&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d0b6780&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d0b6860&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d0b6780&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817d0b6ba8&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d0b6be0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817d0b6860&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817cd9a248&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: / (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d0b6be0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>default_home_request = &lt;server.api.requests.Get object at 0x7f817d0b6438&gt;<br/>success = 200<br/><br/>    @pytest.mark.performance<br/>    def test_smoke(default_home_request: Request, success: int) -&gt; None:<br/>        t1: float = time.time()<br/>        times: int = _xtime<br/>        while times &gt; _zero:<br/>&gt;           assert default_home_request.response().status_code() == success<br/><br/>tests/non_functional/performance/test_smoke.py:16: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817d0b65f8&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817d0b6780&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: / (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817d0b6be0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/non_functional/performance/test_spike.py::test_spike</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cde6c50&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cde6a90&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cde6a58&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817cde6cf8&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cde6a90&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817cde6c50&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cde6cf8&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817cde6ba8&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cde6c50&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cde6c50&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cde6c50&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cde6c50&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cde6c50&gt;<br/>data = b&#x27;GET / HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cde6c50&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cde6c50&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817cde6c50&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817cde67f0&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cde6a58&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cde6a90&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cde6a58&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817cde6cf8&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817cde6c50&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cde6a90&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817cd5a788&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: / (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817cde6c50&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>default_home_request = &lt;server.api.requests.Get object at 0x7f817cde6550&gt;<br/>success = 200<br/><br/>    @pytest.mark.performance<br/>    def test_spike(default_home_request: Request, success: int) -&gt; None:<br/>        times: int = _xtime<br/>        step: List[int] = _step<br/>        while times &gt; _zero:<br/>&gt;           assert default_home_request.response().status_code() == success<br/><br/>tests/non_functional/performance/test_spike.py:18: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817cde67f0&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cde6a58&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: / (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817cde6c50&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/non_functional/performance/test_stress.py::test_stress</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cbf6da0&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>&gt;               (self._dns_host, self.port), self.timeout, **extra_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:171: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>                sock.connect(sa)<br/>                return sock<br/>    <br/>            except socket.error as e:<br/>                err = e<br/>                if sock is not None:<br/>                    sock.close()<br/>                    sock = None<br/>    <br/>        if err is not None:<br/>&gt;           raise err<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>address = (&#x27;localhost&#x27;, 5000), timeout = None, source_address = None<br/>socket_options = [(6, 1, 1)]<br/><br/>    def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,<br/>                          source_address=None, socket_options=None):<br/>        &quot;&quot;&quot;Connect to *address* and return the socket object.<br/>    <br/>        Convenience function.  Connect to *address* (a 2-tuple ``(host,<br/>        port)``) and return the socket object.  Passing the optional<br/>        *timeout* parameter will set the timeout on the socket instance<br/>        before attempting to connect.  If no *timeout* is supplied, the<br/>        global default timeout setting returned by :func:`getdefaulttimeout`<br/>        is used.  If *source_address* is set it must be a tuple of (host, port)<br/>        for the socket to bind as a source address before making the connection.<br/>        An host of &#x27;&#x27; or port 0 tells the OS to use the default.<br/>        &quot;&quot;&quot;<br/>    <br/>        host, port = address<br/>        if host.startswith(&#x27;[&#x27;):<br/>            host = host.strip(&#x27;[]&#x27;)<br/>        err = None<br/>    <br/>        # Using the value from allowed_gai_family() in the context of getaddrinfo lets<br/>        # us select whether to work with IPv4 DNS records, IPv6 records, or both.<br/>        # The original create_connection function always returns all records.<br/>        family = allowed_gai_family()<br/>    <br/>        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):<br/>            af, socktype, proto, canonname, sa = res<br/>            sock = None<br/>            try:<br/>                sock = socket.socket(af, socktype, proto)<br/>    <br/>                # If provided, set socket level options before connecting.<br/>                _set_socket_options(sock, socket_options)<br/>    <br/>                if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:<br/>                    sock.settimeout(timeout)<br/>                if source_address:<br/>                    sock.bind(source_address)<br/>&gt;               sock.connect(sa)<br/><span class="error">E               ConnectionRefusedError: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/connection.py:69: ConnectionRefusedError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cbf6a20&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cbf6940&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817cbf6d68&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>&gt;                                                 chunked=chunked)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:600: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cbf6a20&gt;<br/>conn = &lt;urllib3.connection.HTTPConnection object at 0x7f817cbf6da0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cbf6d68&gt;<br/>chunked = False<br/>httplib_request_kw = {&#x27;body&#x27;: None, &#x27;headers&#x27;: {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}}<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817cbf6dd8&gt;<br/><br/>    def _make_request(self, conn, method, url, timeout=_Default, chunked=False,<br/>                      **httplib_request_kw):<br/>        &quot;&quot;&quot;<br/>            Perform a request on a given urllib connection object taken from our<br/>            pool.<br/>    <br/>            :param conn:<br/>                a connection from one of our connection pools<br/>    <br/>            :param timeout:<br/>                Socket timeout in seconds for the request. This can be a<br/>                float or integer, which will set the same timeout value for<br/>                the socket connect and the socket read, or an instance of<br/>                :class:`urllib3.util.Timeout`, which gives you more fine-grained<br/>                control over your timeouts.<br/>            &quot;&quot;&quot;<br/>        self.num_requests += 1<br/>    <br/>        timeout_obj = self._get_timeout(timeout)<br/>        timeout_obj.start_connect()<br/>        conn.timeout = timeout_obj.connect_timeout<br/>    <br/>        # Trigger any extra validation we need to do.<br/>        try:<br/>            self._validate_conn(conn)<br/>        except (SocketTimeout, BaseSSLError) as e:<br/>            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.<br/>            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)<br/>            raise<br/>    <br/>        # conn.request() calls httplib.*.request, not the method in<br/>        # urllib3.request. It also calls makefile (recv) on the socket.<br/>        if chunked:<br/>            conn.request_chunked(method, url, **httplib_request_kw)<br/>        else:<br/>&gt;           conn.request(method, url, **httplib_request_kw)<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:354: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cbf6da0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/><br/>    def request(self, method, url, body=None, headers={}, *,<br/>                encode_chunked=False):<br/>        &quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;<br/>&gt;       self._send_request(method, url, body, headers, encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1239: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cbf6da0&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>encode_chunked = False<br/><br/>    def _send_request(self, method, url, body, headers, encode_chunked):<br/>        # Honor explicitly requested Host: and Accept-Encoding: headers.<br/>        header_names = frozenset(k.lower() for k in headers)<br/>        skips = {}<br/>        if &#x27;host&#x27; in header_names:<br/>            skips[&#x27;skip_host&#x27;] = 1<br/>        if &#x27;accept-encoding&#x27; in header_names:<br/>            skips[&#x27;skip_accept_encoding&#x27;] = 1<br/>    <br/>        self.putrequest(method, url, **skips)<br/>    <br/>        # chunked encoding will happen if HTTP/1.1 is used and either<br/>        # the caller passes encode_chunked=True or the following<br/>        # conditions hold:<br/>        # 1. content-length has not been explicitly set<br/>        # 2. the body is a file or iterable, but not a str or bytes-like<br/>        # 3. Transfer-Encoding has NOT been explicitly set by the caller<br/>    <br/>        if &#x27;content-length&#x27; not in header_names:<br/>            # only chunk body if not explicitly set for backwards<br/>            # compatibility, assuming the client code is already handling the<br/>            # chunking<br/>            if &#x27;transfer-encoding&#x27; not in header_names:<br/>                # if content-length cannot be automatically determined, fall<br/>                # back to chunked encoding<br/>                encode_chunked = False<br/>                content_length = self._get_content_length(body, method)<br/>                if content_length is None:<br/>                    if body is not None:<br/>                        if self.debuglevel &gt; 0:<br/>                            print(&#x27;Unable to determine size of %r&#x27; % body)<br/>                        encode_chunked = True<br/>                        self.putheader(&#x27;Transfer-Encoding&#x27;, &#x27;chunked&#x27;)<br/>                else:<br/>                    self.putheader(&#x27;Content-Length&#x27;, str(content_length))<br/>        else:<br/>            encode_chunked = False<br/>    <br/>        for hdr, value in headers.items():<br/>            self.putheader(hdr, value)<br/>        if isinstance(body, str):<br/>            # RFC 2616 Section 3.7.1 says that text default has a<br/>            # default charset of iso-8859-1.<br/>            body = _encode(body, &#x27;body&#x27;)<br/>&gt;       self.endheaders(body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1285: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cbf6da0&gt;<br/>message_body = None<br/><br/>    def endheaders(self, message_body=None, *, encode_chunked=False):<br/>        &quot;&quot;&quot;Indicate that the last header line has been sent to the server.<br/>    <br/>            This method sends the request to the server.  The optional message_body<br/>            argument can be used to pass a message body associated with the<br/>            request.<br/>            &quot;&quot;&quot;<br/>        if self.__state == _CS_REQ_STARTED:<br/>            self.__state = _CS_REQ_SENT<br/>        else:<br/>            raise CannotSendHeader()<br/>&gt;       self._send_output(message_body, encode_chunked=encode_chunked)<br/><br/>/usr/local/lib/python3.6/http/client.py:1234: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cbf6da0&gt;<br/>message_body = None, encode_chunked = False<br/><br/>    def _send_output(self, message_body=None, encode_chunked=False):<br/>        &quot;&quot;&quot;Send the currently buffered request and clear the buffer.<br/>    <br/>            Appends an extra \\r\\n to the buffer.<br/>            A message_body may be specified, to be appended to the request.<br/>            &quot;&quot;&quot;<br/>        self._buffer.extend((b&quot;&quot;, b&quot;&quot;))<br/>        msg = b&quot;\r\n&quot;.join(self._buffer)<br/>        del self._buffer[:]<br/>&gt;       self.send(msg)<br/><br/>/usr/local/lib/python3.6/http/client.py:1026: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cbf6da0&gt;<br/>data = b&#x27;GET / HTTP/1.1\r\nHost: localhost:5000\r\nUser-Agent: python-requests/2.19.1\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;<br/><br/>    def send(self, data):<br/>        &quot;&quot;&quot;Send `data&#x27; to the server.<br/>            ``data`` can be a string object, a bytes object, an array object, a<br/>            file-like object that supports a .read() method, or an iterable object.<br/>            &quot;&quot;&quot;<br/>    <br/>        if self.sock is None:<br/>            if self.auto_open:<br/>&gt;               self.connect()<br/><br/>/usr/local/lib/python3.6/http/client.py:964: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cbf6da0&gt;<br/><br/>    def connect(self):<br/>&gt;       conn = self._new_conn()<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:196: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connection.HTTPConnection object at 0x7f817cbf6da0&gt;<br/><br/>    def _new_conn(self):<br/>        &quot;&quot;&quot; Establish a socket connection and set nodelay settings on it.<br/>    <br/>            :return: New socket connection.<br/>            &quot;&quot;&quot;<br/>        extra_kw = {}<br/>        if self.source_address:<br/>            extra_kw[&#x27;source_address&#x27;] = self.source_address<br/>    <br/>        if self.socket_options:<br/>            extra_kw[&#x27;socket_options&#x27;] = self.socket_options<br/>    <br/>        try:<br/>            conn = connection.create_connection(<br/>                (self._dns_host, self.port), self.timeout, **extra_kw)<br/>    <br/>        except SocketTimeout as e:<br/>            raise ConnectTimeoutError(<br/>                self, &quot;Connection to %s timed out. (connect timeout=%s)&quot; %<br/>                (self.host, self.timeout))<br/>    <br/>        except SocketError as e:<br/>            raise NewConnectionError(<br/>&gt;               self, &quot;Failed to establish a new connection: %s&quot; % e)<br/><span class="error">E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x7f817cbf6da0&gt;: Failed to establish a new connection: [Errno 111] Connection refused</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connection.py:180: NewConnectionError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817cbf67b8&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cbf6940&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>&gt;                   timeout=timeout<br/>                )<br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:445: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cbf6a20&gt;<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, body = None<br/>headers = {&#x27;User-Agent&#x27;: &#x27;python-requests/2.19.1&#x27;, &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;, &#x27;Accept&#x27;: &#x27;*/*&#x27;, &#x27;Connection&#x27;: &#x27;keep-alive&#x27;}<br/>retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>redirect = False, assert_same_host = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cbf6940&gt;<br/>pool_timeout = None, release_conn = False, chunked = False, body_pos = None<br/>response_kw = {&#x27;decode_content&#x27;: False, &#x27;preload_content&#x27;: False}, conn = None<br/>release_this_conn = True, err = None, clean_exit = False<br/>timeout_obj = &lt;urllib3.util.timeout.Timeout object at 0x7f817cbf6d68&gt;<br/>is_new_proxy_conn = False<br/><br/>    def urlopen(self, method, url, body=None, headers=None, retries=None,<br/>                redirect=True, assert_same_host=True, timeout=_Default,<br/>                pool_timeout=None, release_conn=None, chunked=False,<br/>                body_pos=None, **response_kw):<br/>        &quot;&quot;&quot;<br/>            Get a connection from the pool and perform an HTTP request. This is the<br/>            lowest level call for making a request, so you&#x27;ll need to specify all<br/>            the raw details.<br/>    <br/>            .. note::<br/>    <br/>               More commonly, it&#x27;s appropriate to use a convenience method provided<br/>               by :class:`.RequestMethods`, such as :meth:`request`.<br/>    <br/>            .. note::<br/>    <br/>               `release_conn` will only behave as expected if<br/>               `preload_content=False` because we want to make<br/>               `preload_content=False` the default behaviour someday soon without<br/>               breaking backwards compatibility.<br/>    <br/>            :param method:<br/>                HTTP request method (such as GET, POST, PUT, etc.)<br/>    <br/>            :param body:<br/>                Data to send in the request body (useful for creating<br/>                POST requests, see HTTPConnectionPool.post_url for<br/>                more convenience).<br/>    <br/>            :param headers:<br/>                Dictionary of custom headers to send, such as User-Agent,<br/>                If-None-Match, etc. If None, pool headers are used. If provided,<br/>                these headers completely replace any pool-specific headers.<br/>    <br/>            :param retries:<br/>                Configure the number of retries to allow before raising a<br/>                :class:`~urllib3.exceptions.MaxRetryError` exception.<br/>    <br/>                Pass ``None`` to retry until you receive a response. Pass a<br/>                :class:`~urllib3.util.retry.Retry` object for fine-grained control<br/>                over different types of retries.<br/>                Pass an integer number to retry connection errors that many times,<br/>                but no other types of errors. Pass zero to never retry.<br/>    <br/>                If ``False``, then retries are disabled and any exception is raised<br/>                immediately. Also, instead of raising a MaxRetryError on redirects,<br/>                the redirect response will be returned.<br/>    <br/>            :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.<br/>    <br/>            :param redirect:<br/>                If True, automatically handle redirects (status codes 301, 302,<br/>                303, 307, 308). Each redirect counts as a retry. Disabling retries<br/>                will disable redirect, too.<br/>    <br/>            :param assert_same_host:<br/>                If ``True``, will make sure that the host of the pool requests is<br/>                consistent else will raise HostChangedError. When False, you can<br/>                use the pool on an HTTP proxy and request foreign hosts.<br/>    <br/>            :param timeout:<br/>                If specified, overrides the default timeout for this one<br/>                request. It may be a float (in seconds) or an instance of<br/>                :class:`urllib3.util.Timeout`.<br/>    <br/>            :param pool_timeout:<br/>                If set and the pool is set to block=True, then this method will<br/>                block for ``pool_timeout`` seconds and raise EmptyPoolError if no<br/>                connection is available within the time period.<br/>    <br/>            :param release_conn:<br/>                If False, then the urlopen call will not release the connection<br/>                back into the pool once a response is received (but will release if<br/>                you read the entire contents of the response such as when<br/>                `preload_content=True`). This is useful if you&#x27;re not preloading<br/>                the response&#x27;s content immediately. You will need to call<br/>                ``r.release_conn()`` on the response ``r`` to return the connection<br/>                back into the pool. If None, it takes the value of<br/>                ``response_kw.get(&#x27;preload_content&#x27;, True)``.<br/>    <br/>            :param chunked:<br/>                If True, urllib3 will send the body using chunked transfer<br/>                encoding. Otherwise, urllib3 will send the body using the standard<br/>                content-length form. Defaults to False.<br/>    <br/>            :param int body_pos:<br/>                Position to seek to in file-like body in the event of a retry or<br/>                redirect. Typically this won&#x27;t need to be set because urllib3 will<br/>                auto-populate the value when needed.<br/>    <br/>            :param \\**response_kw:<br/>                Additional parameters are passed to<br/>                :meth:`urllib3.response.HTTPResponse.from_httplib`<br/>            &quot;&quot;&quot;<br/>        if headers is None:<br/>            headers = self.headers<br/>    <br/>        if not isinstance(retries, Retry):<br/>            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)<br/>    <br/>        if release_conn is None:<br/>            release_conn = response_kw.get(&#x27;preload_content&#x27;, True)<br/>    <br/>        # Check host<br/>        if assert_same_host and not self.is_same_host(url):<br/>            raise HostChangedError(self, url, retries)<br/>    <br/>        conn = None<br/>    <br/>        # Track whether `conn` needs to be released before<br/>        # returning/raising/recursing. Update this variable if necessary, and<br/>        # leave `release_conn` constant throughout the function. That way, if<br/>        # the function recurses, the original value of `release_conn` will be<br/>        # passed down into the recursive call, and its value will be respected.<br/>        #<br/>        # See issue #651 [1] for details.<br/>        #<br/>        # [1] &lt;https://github.com/shazow/urllib3/issues/651&gt;<br/>        release_this_conn = release_conn<br/>    <br/>        # Merge the proxy headers. Only do this in HTTP. We have to copy the<br/>        # headers dict so we can safely change it without those changes being<br/>        # reflected in anyone else&#x27;s copy.<br/>        if self.scheme == &#x27;http&#x27;:<br/>            headers = headers.copy()<br/>            headers.update(self.proxy_headers)<br/>    <br/>        # Must keep the exception bound to a separate variable or else Python 3<br/>        # complains about UnboundLocalError.<br/>        err = None<br/>    <br/>        # Keep track of whether we cleanly exited the except block. This<br/>        # ensures we do proper cleanup in finally.<br/>        clean_exit = False<br/>    <br/>        # Rewind body position, if needed. Record current position<br/>        # for future rewinds in the event of a redirect/retry.<br/>        body_pos = set_file_position(body, body_pos)<br/>    <br/>        try:<br/>            # Request a connection from the queue.<br/>            timeout_obj = self._get_timeout(timeout)<br/>            conn = self._get_conn(timeout=pool_timeout)<br/>    <br/>            conn.timeout = timeout_obj.connect_timeout<br/>    <br/>            is_new_proxy_conn = self.proxy is not None and not getattr(conn, &#x27;sock&#x27;, None)<br/>            if is_new_proxy_conn:<br/>                self._prepare_proxy(conn)<br/>    <br/>            # Make the request on the httplib connection object.<br/>            httplib_response = self._make_request(conn, method, url,<br/>                                                  timeout=timeout_obj,<br/>                                                  body=body, headers=headers,<br/>                                                  chunked=chunked)<br/>    <br/>            # If we&#x27;re going to release the connection in ``finally:``, then<br/>            # the response doesn&#x27;t need to know about the connection. Otherwise<br/>            # it will also try to release it and we&#x27;ll have a double-release<br/>            # mess.<br/>            response_conn = conn if not release_conn else None<br/>    <br/>            # Pass method to Response for length checking<br/>            response_kw[&#x27;request_method&#x27;] = method<br/>    <br/>            # Import httplib&#x27;s response into our own wrapper object<br/>            response = self.ResponseCls.from_httplib(httplib_response,<br/>                                                     pool=self,<br/>                                                     connection=response_conn,<br/>                                                     retries=retries,<br/>                                                     **response_kw)<br/>    <br/>            # Everything went great!<br/>            clean_exit = True<br/>    <br/>        except queue.Empty:<br/>            # Timed out by queue.<br/>            raise EmptyPoolError(self, &quot;No pool connections are available.&quot;)<br/>    <br/>        except (TimeoutError, HTTPException, SocketError, ProtocolError,<br/>                BaseSSLError, SSLError, CertificateError) as e:<br/>            # Discard the connection for these exceptions. It will be<br/>            # replaced during the next _get_conn() call.<br/>            clean_exit = False<br/>            if isinstance(e, (BaseSSLError, CertificateError)):<br/>                e = SSLError(e)<br/>            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:<br/>                e = ProxyError(&#x27;Cannot connect to proxy.&#x27;, e)<br/>            elif isinstance(e, (SocketError, HTTPException)):<br/>                e = ProtocolError(&#x27;Connection aborted.&#x27;, e)<br/>    <br/>            retries = retries.increment(method, url, error=e, _pool=self,<br/>&gt;                                       _stacktrace=sys.exc_info()[2])<br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py:638: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = Retry(total=0, connect=None, read=False, redirect=None, status=None)<br/>method = &#x27;GET&#x27;, url = &#x27;/&#x27;, response = None<br/>error = NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817cbf6da0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,)<br/>_pool = &lt;urllib3.connectionpool.HTTPConnectionPool object at 0x7f817cbf6a20&gt;<br/>_stacktrace = &lt;traceback object at 0x7f817dd032c8&gt;<br/><br/>    def increment(self, method=None, url=None, response=None, error=None,<br/>                  _pool=None, _stacktrace=None):<br/>        &quot;&quot;&quot; Return a new Retry object with incremented retry counters.<br/>    <br/>            :param response: A response object, or None, if the server did not<br/>                return a response.<br/>            :type response: :class:`~urllib3.response.HTTPResponse`<br/>            :param Exception error: An error encountered during the request, or<br/>                None if the response was received successfully.<br/>    <br/>            :return: A new ``Retry`` object.<br/>            &quot;&quot;&quot;<br/>        if self.total is False and error:<br/>            # Disabled, indicate to re-raise the error.<br/>            raise six.reraise(type(error), error, _stacktrace)<br/>    <br/>        total = self.total<br/>        if total is not None:<br/>            total -= 1<br/>    <br/>        connect = self.connect<br/>        read = self.read<br/>        redirect = self.redirect<br/>        status_count = self.status<br/>        cause = &#x27;unknown&#x27;<br/>        status = None<br/>        redirect_location = None<br/>    <br/>        if error and self._is_connection_error(error):<br/>            # Connect retry?<br/>            if connect is False:<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif connect is not None:<br/>                connect -= 1<br/>    <br/>        elif error and self._is_read_error(error):<br/>            # Read retry?<br/>            if read is False or not self._is_method_retryable(method):<br/>                raise six.reraise(type(error), error, _stacktrace)<br/>            elif read is not None:<br/>                read -= 1<br/>    <br/>        elif response and response.get_redirect_location():<br/>            # Redirect retry?<br/>            if redirect is not None:<br/>                redirect -= 1<br/>            cause = &#x27;too many redirects&#x27;<br/>            redirect_location = response.get_redirect_location()<br/>            status = response.status<br/>    <br/>        else:<br/>            # Incrementing because of a server error like a 500 in<br/>            # status_forcelist and a the given method is in the whitelist<br/>            cause = ResponseError.GENERIC_ERROR<br/>            if response and response.status:<br/>                if status_count is not None:<br/>                    status_count -= 1<br/>                cause = ResponseError.SPECIFIC_ERROR.format(<br/>                    status_code=response.status)<br/>                status = response.status<br/>    <br/>        history = self.history + (RequestHistory(method, url, error, status, redirect_location),)<br/>    <br/>        new_retry = self.new(<br/>            total=total,<br/>            connect=connect, read=read, redirect=redirect, status=status_count,<br/>            history=history)<br/>    <br/>        if new_retry.is_exhausted():<br/>&gt;           raise MaxRetryError(_pool, url, error or ResponseError(cause))<br/><span class="error">E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: / (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817cbf6da0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py:398: MaxRetryError<br/><br/>During handling of the above exception, another exception occurred:<br/><br/>default_home_request = &lt;server.api.requests.Get object at 0x7f817cbf6550&gt;<br/>success = 200<br/><br/>    @pytest.mark.performance<br/>    def test_stress(default_home_request: Request, success: int) -&gt; None:<br/>        t1: float = time.time()<br/>        times: int = _xtime<br/>        while times &gt; _zero:<br/>&gt;           assert default_home_request.response().status_code() == success<br/><br/>tests/non_functional/performance/test_stress.py:16: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/>server/api/requests.py:23: in response<br/>    return HttpResponse(self._session.get(self._url, **kwargs, verify=False))<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:525: in get<br/>    return self.request(&#x27;GET&#x27;, url, **kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:512: in request<br/>    resp = self.send(prep, **send_kwargs)<br/>/usr/local/lib/python3.6/site-packages/requests/sessions.py:622: in send<br/>    r = adapter.send(request, **kwargs)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ <br/><br/>self = &lt;requests.adapters.HTTPAdapter object at 0x7f817cbf67b8&gt;<br/>request = &lt;PreparedRequest [GET]&gt;, stream = False<br/>timeout = &lt;urllib3.util.timeout.Timeout object at 0x7f817cbf6940&gt;<br/>verify = False, cert = None, proxies = OrderedDict()<br/><br/>    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):<br/>        &quot;&quot;&quot;Sends PreparedRequest object. Returns Response object.<br/>    <br/>            :param request: The :class:`PreparedRequest &lt;PreparedRequest&gt;` being sent.<br/>            :param stream: (optional) Whether to stream the request content.<br/>            :param timeout: (optional) How long to wait for the server to send<br/>                data before giving up, as a float, or a :ref:`(connect timeout,<br/>                read timeout) &lt;timeouts&gt;` tuple.<br/>            :type timeout: float or tuple or urllib3 Timeout object<br/>            :param verify: (optional) Either a boolean, in which case it controls whether<br/>                we verify the server&#x27;s TLS certificate, or a string, in which case it<br/>                must be a path to a CA bundle to use<br/>            :param cert: (optional) Any user-provided SSL certificate to be trusted.<br/>            :param proxies: (optional) The proxies dictionary to apply to the request.<br/>            :rtype: requests.Response<br/>            &quot;&quot;&quot;<br/>    <br/>        conn = self.get_connection(request.url, proxies)<br/>    <br/>        self.cert_verify(conn, request.url, verify, cert)<br/>        url = self.request_url(request, proxies)<br/>        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)<br/>    <br/>        chunked = not (request.body is None or &#x27;Content-Length&#x27; in request.headers)<br/>    <br/>        if isinstance(timeout, tuple):<br/>            try:<br/>                connect, read = timeout<br/>                timeout = TimeoutSauce(connect=connect, read=read)<br/>            except ValueError as e:<br/>                # this may raise a string formatting error.<br/>                err = (&quot;Invalid timeout {0}. Pass a (connect, read) &quot;<br/>                       &quot;timeout tuple, or a single float to set &quot;<br/>                       &quot;both timeouts to the same value&quot;.format(timeout))<br/>                raise ValueError(err)<br/>        elif isinstance(timeout, TimeoutSauce):<br/>            pass<br/>        else:<br/>            timeout = TimeoutSauce(connect=timeout, read=timeout)<br/>    <br/>        try:<br/>            if not chunked:<br/>                resp = conn.urlopen(<br/>                    method=request.method,<br/>                    url=url,<br/>                    body=request.body,<br/>                    headers=request.headers,<br/>                    redirect=False,<br/>                    assert_same_host=False,<br/>                    preload_content=False,<br/>                    decode_content=False,<br/>                    retries=self.max_retries,<br/>                    timeout=timeout<br/>                )<br/>    <br/>            # Send the request.<br/>            else:<br/>                if hasattr(conn, &#x27;proxy_pool&#x27;):<br/>                    conn = conn.proxy_pool<br/>    <br/>                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)<br/>    <br/>                try:<br/>                    low_conn.putrequest(request.method,<br/>                                        url,<br/>                                        skip_accept_encoding=True)<br/>    <br/>                    for header, value in request.headers.items():<br/>                        low_conn.putheader(header, value)<br/>    <br/>                    low_conn.endheaders()<br/>    <br/>                    for i in request.body:<br/>                        low_conn.send(hex(len(i))[2:].encode(&#x27;utf-8&#x27;))<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                        low_conn.send(i)<br/>                        low_conn.send(b&#x27;\r\n&#x27;)<br/>                    low_conn.send(b&#x27;0\r\n\r\n&#x27;)<br/>    <br/>                    # Receive the response from the server<br/>                    try:<br/>                        # For Python 2.7+ versions, use buffering of HTTP<br/>                        # responses<br/>                        r = low_conn.getresponse(buffering=True)<br/>                    except TypeError:<br/>                        # For compatibility with Python 2.6 versions and back<br/>                        r = low_conn.getresponse()<br/>    <br/>                    resp = HTTPResponse.from_httplib(<br/>                        r,<br/>                        pool=conn,<br/>                        connection=low_conn,<br/>                        preload_content=False,<br/>                        decode_content=False<br/>                    )<br/>                except:<br/>                    # If we hit any problems here, clean up the connection.<br/>                    # Then, reraise so that we can handle the actual exception.<br/>                    low_conn.close()<br/>                    raise<br/>    <br/>        except (ProtocolError, socket.error) as err:<br/>            raise ConnectionError(err, request=request)<br/>    <br/>        except MaxRetryError as e:<br/>            if isinstance(e.reason, ConnectTimeoutError):<br/>                # TODO: Remove this in 3.0.0: see #2811<br/>                if not isinstance(e.reason, NewConnectionError):<br/>                    raise ConnectTimeout(e, request=request)<br/>    <br/>            if isinstance(e.reason, ResponseError):<br/>                raise RetryError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _ProxyError):<br/>                raise ProxyError(e, request=request)<br/>    <br/>            if isinstance(e.reason, _SSLError):<br/>                # This branch is for urllib3 v1.22 and later.<br/>                raise SSLError(e, request=request)<br/>    <br/>&gt;           raise ConnectionError(e, request=request)<br/><span class="error">E           requests.exceptions.ConnectionError: HTTPConnectionPool(host=&#x27;localhost&#x27;, port=5000): Max retries exceeded with url: / (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f817cbf6da0&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;,))</span><br/><br/>/usr/local/lib/python3.6/site-packages/requests/adapters.py:513: ConnectionError<br/></div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/functional/unitests/test_posts.py::test_post_date</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody>
      <tbody class="passed results-table-row">
        <tr>
          <td class="col-result">Passed</td>
          <td class="col-name">tests/functional/unitests/test_posts.py::test_blog_post</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="empty log">No log output captured.</div></td></tr></tbody></table></body></html>